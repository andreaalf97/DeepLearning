{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jc_c74bzwvJw"
   },
   "source": [
    "# Deep Learning Project\n",
    "## CIFAR 10 dropout notebook\n",
    "\n",
    "#### Gaussian, no batch norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-PBra8kx5OE"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXg7wMRMwusn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1SAfkKTyBZo"
   },
   "source": [
    "### Download the dataset, transform it and divide into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "999d6959943242a69f2ddb6b9bf03ce9",
      "3fab2f120a50450188abd409c96a0336",
      "7b186e8dcdbd4f66b288b8b64b7232f4",
      "3ef5113b7cf241bb86f0092178a8d1e6",
      "dd2bf7be43e445549daa04091cbf1f88",
      "11e1a9ac34f047848baa8ffbb2a7159a",
      "f9f368cd4cf94047bdcb77523db25b40",
      "64b566dfbafd4603b89e434a537a6935"
     ]
    },
    "colab_type": "code",
    "id": "8n4xJY-fx7BB",
    "outputId": "de279b9a-11f6-4d99-9ea8-44ac80943f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999d6959943242a69f2ddb6b9bf03ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "# Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
    "\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [0, 1].\n",
    "\n",
    "# This trasnform is the GLOBAL CONTRAST NORMALIZATION, for which the parameters have been calculated at the end of this notebook\n",
    "transform =transforms.Compose(\n",
    "    [      \n",
    "    transforms.ToTensor(),  # Dataset images are in Pillow format, but we need them as tensors\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2427, 0.2392, 0.2559))\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainSet = torchvision.datasets.CIFAR10(\n",
    "    root='./data',  # where the dataset is/will be stored\n",
    "    train=True,  # creates the dataset FROM the train set\n",
    "    download=False,  # If True, downloads the dataset from the internet\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "# This combines a dataset and a sampler, and provides an iterable over the given dataset\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    trainSet,  # The dataset\n",
    "    batch_size=100,  # How many samples per batch to load\n",
    "    shuffle=True, # Data is reshuffled at every epoch\n",
    "    num_workers=2 # How many processes to use for data loading\n",
    ")\n",
    "\n",
    "classes = (\n",
    "    'plane',\n",
    "    'car',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrtTiPQ_y0-1"
   },
   "source": [
    "### Model with Gaussian dropout\n",
    "**In this case, we had to implement the dropout manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CKZv4rSywtE"
   },
   "outputs": [],
   "source": [
    "# DEFINING A CONVOLUTIONAL NEURAL NETWORK\n",
    "\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "         \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(num_features=2048)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(num_features=1024)\n",
    "        \n",
    "        self.bnc1 = nn.BatchNorm2d(num_features=96)\n",
    "        \n",
    "        self.bnc2 = nn.BatchNorm2d(num_features=128)\n",
    "        \n",
    "        self.bnc3 = nn.BatchNorm2d(num_features=256) \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 96, 5, padding=2, stride = 1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(96, 128, 5,padding=2, stride = 1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128,256, 5, padding=2, stride = 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(2304, 2048)\n",
    "\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1024,10)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(3, 2)\n",
    "        \n",
    "        \n",
    "        self.p1=0.9\n",
    "        self.p2=0.75\n",
    "        self.p3=0.5\n",
    "        \n",
    "        self.sigma1 = np.sqrt((1-self.p1)/self.p1)\n",
    "        self.sigma2 = np.sqrt((1-self.p2)/self.p2)\n",
    "        self.sigma3 = np.sqrt((1-self.p3)/self.p3)\n",
    "\n",
    "    def gaussian_dropout(self, x, std, mean):\n",
    "        epsilon = torch.randn(x.size()) * std + mean\n",
    "        epsilon = epsilon.cuda()\n",
    "        return epsilon * x\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.gaussian_dropout(x, self.sigma1, 1)  # Comment this out to remove dropout\n",
    "        x = (self.pool(F.relu((self.bnc1(self.conv1(x))))))\n",
    "        \n",
    "        x = self.gaussian_dropout(x, self.sigma2, 1)  # Comment this out to remove dropout\n",
    "        x = (self.pool(F.relu(self.bnc2((self.conv2(x))))))\n",
    "        \n",
    "        x = self.gaussian_dropout(x, self.sigma2, 1)  # Comment this out to remove dropout\n",
    "        x = (self.pool(F.relu(self.bnc3((self.conv3(x))))))\n",
    "        \n",
    "        x = x.view(-1, 2304)\n",
    "        x = self.gaussian_dropout(x, self.sigma3, 1)  # Comment this out to remove dropout\n",
    "        x = (F.relu(self.bn1(self.fc1(x))))\n",
    "                \n",
    "        x = self.gaussian_dropout(x, self.sigma3, 1)  # Comment this out to remove dropout\n",
    "        x = (F.relu(self.bn2(self.fc2(x))))\n",
    "            \n",
    "        x = self.gaussian_dropout(x, self.sigma3, 1)  # Comment this out to remove dropout\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4TUokm4ezCpo"
   },
   "source": [
    "## Initialization\n",
    "### Then we set all parameters for the testing phase\n",
    "\n",
    "For the Linear layer, we decided to initialize the weights through a uniform distribution. Following the work of \"*Understanding the difficulty of training deep feedforward neural networks*\" by Glorot et al., we fill in the tensors with values sampled from $\\mathit{U}(-a, a)$, where \n",
    "\n",
    "$a = \\mathrm{gain} \\cdot \\sqrt{\\frac{6}{\\mathrm{fan\\_in} + \\mathrm{fan\\_out}}} $\n",
    "\n",
    "This is also known as Glorot initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "T1jUw4diy-TR",
    "outputId": "bc2d58ef-ac49-441d-e9f9-cb29401259dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print(\"Using GPU\" if use_gpu else \"Not using GPU\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        #weight initialisation\n",
    "        nn.init.xavier_uniform_(\n",
    "            m.weight, \n",
    "            gain=nn.init.calculate_gain('relu') # this returns the recommended gain for the given non linearity\n",
    "        )\n",
    "        #nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        #constant bias.\n",
    "        m.bias.data.fill_(-0.05)\n",
    "    if type(m) == nn.Conv2d:\n",
    "        #weight initialisation\n",
    "        nn.init.xavier_uniform_(m.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        #nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        #constant bias\n",
    "        m.bias.data.fill_(-0.05)\n",
    "\n",
    "net = Net()  # Initialize the Net class\n",
    "net.apply(init_weights) # This applies the initialization recursively over all modules of Net\n",
    "\n",
    "if use_gpu:\n",
    "    net = net.cuda()\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "# This already has a SOFTMAX layer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=0.002, momentum=0.8, weight_decay=0.001\n",
    ")\n",
    "\n",
    "#optimizer =optim.Adam(net.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False, )\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, 0.0012, .00044, step_size_up=2000, step_size_down=None, mode='triangular', \n",
    "                                                    #       gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, \n",
    "                                                   #        max_momentum=0.9, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JItkOWr8M8DC"
   },
   "source": [
    "## Finally, we train our model\n",
    "\n",
    "**First, we define the ZCA Whitening function and apply it during training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONGJmAwverw8"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(\"./runs\")\n",
    "\n",
    "def zca(inputs):\n",
    "    \n",
    "    initial_shape = inputs.shape\n",
    "  # print(inputs.shape)\n",
    "  \n",
    "    inputs=inputs.reshape(initial_shape[0],-1) # flattening\n",
    "  # print(inputs.shape)\n",
    "\n",
    "    X = inputs\n",
    "    X = X - X.mean(axis=0)\n",
    "  # compute the covariance of the image data\n",
    "\n",
    "    cov = np.cov(X, rowvar=True)   # cov is (N, N)\n",
    "  # singular value decomposition\n",
    "    U,S,V = np.linalg.svd(cov)     # U is (N, N), S is (N,)\n",
    "  # build the ZCA matrix\n",
    "    epsilon = 1e-15\n",
    "    zca_matrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T))\n",
    "  # transform the image data       zca_matrix is (N,N)\n",
    "    zca = np.dot(zca_matrix,X)    # zca is (N, 3072)\n",
    "\n",
    "    return zca.reshape(initial_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O611KOHXzFvt",
    "outputId": "3b2d5077-b83a-4bb9-f918-0368d1739a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.617\n",
      "[1,   200] loss: 2.297\n",
      "[1,   300] loss: 2.289\n",
      "[1,   400] loss: 2.262\n",
      "[1,   500] loss: 2.221\n",
      "[2,   100] loss: 2.190\n",
      "[2,   200] loss: 2.161\n",
      "[2,   300] loss: 2.135\n",
      "[2,   400] loss: 2.106\n",
      "[2,   500] loss: 2.084\n",
      "[3,   100] loss: 2.070\n",
      "[3,   200] loss: 2.056\n",
      "[3,   300] loss: 2.053\n",
      "[3,   400] loss: 2.030\n",
      "[3,   500] loss: 2.009\n",
      "[4,   100] loss: 2.004\n",
      "[4,   200] loss: 1.984\n",
      "[4,   300] loss: 1.968\n",
      "[4,   400] loss: 1.961\n",
      "[4,   500] loss: 1.967\n",
      "[5,   100] loss: 1.951\n",
      "[5,   200] loss: 1.925\n",
      "[5,   300] loss: 1.937\n",
      "[5,   400] loss: 1.908\n",
      "[5,   500] loss: 1.902\n",
      "[6,   100] loss: 1.889\n",
      "[6,   200] loss: 1.867\n",
      "[6,   300] loss: 1.865\n",
      "[6,   400] loss: 1.844\n",
      "[6,   500] loss: 1.833\n",
      "[7,   100] loss: 1.816\n",
      "[7,   200] loss: 1.812\n",
      "[7,   300] loss: 1.782\n",
      "[7,   400] loss: 1.801\n",
      "[7,   500] loss: 1.748\n",
      "[8,   100] loss: 1.743\n",
      "[8,   200] loss: 1.720\n",
      "[8,   300] loss: 1.724\n",
      "[8,   400] loss: 1.717\n",
      "[8,   500] loss: 1.708\n",
      "[9,   100] loss: 1.676\n",
      "[9,   200] loss: 1.692\n",
      "[9,   300] loss: 1.661\n",
      "[9,   400] loss: 1.644\n",
      "[9,   500] loss: 1.619\n",
      "[10,   100] loss: 1.644\n",
      "[10,   200] loss: 1.601\n",
      "[10,   300] loss: 1.571\n",
      "[10,   400] loss: 1.569\n",
      "[10,   500] loss: 1.578\n",
      "[11,   100] loss: 1.568\n",
      "[11,   200] loss: 1.529\n",
      "[11,   300] loss: 1.555\n",
      "[11,   400] loss: 1.550\n",
      "[11,   500] loss: 1.503\n",
      "[12,   100] loss: 1.504\n",
      "[12,   200] loss: 1.482\n",
      "[12,   300] loss: 1.471\n",
      "[12,   400] loss: 1.468\n",
      "[12,   500] loss: 1.432\n",
      "[13,   100] loss: 1.446\n",
      "[13,   200] loss: 1.432\n",
      "[13,   300] loss: 1.460\n",
      "[13,   400] loss: 1.427\n",
      "[13,   500] loss: 1.403\n",
      "[14,   100] loss: 1.391\n",
      "[14,   200] loss: 1.391\n",
      "[14,   300] loss: 1.381\n",
      "[14,   400] loss: 1.394\n",
      "[14,   500] loss: 1.355\n",
      "[15,   100] loss: 1.347\n",
      "[15,   200] loss: 1.352\n",
      "[15,   300] loss: 1.336\n",
      "[15,   400] loss: 1.347\n",
      "[15,   500] loss: 1.331\n",
      "[16,   100] loss: 1.319\n",
      "[16,   200] loss: 1.319\n",
      "[16,   300] loss: 1.308\n",
      "[16,   400] loss: 1.317\n",
      "[16,   500] loss: 1.288\n",
      "[17,   100] loss: 1.274\n",
      "[17,   200] loss: 1.284\n",
      "[17,   300] loss: 1.274\n",
      "[17,   400] loss: 1.256\n",
      "[17,   500] loss: 1.245\n",
      "[18,   100] loss: 1.248\n",
      "[18,   200] loss: 1.241\n",
      "[18,   300] loss: 1.236\n",
      "[18,   400] loss: 1.230\n",
      "[18,   500] loss: 1.227\n",
      "[19,   100] loss: 1.219\n",
      "[19,   200] loss: 1.203\n",
      "[19,   300] loss: 1.226\n",
      "[19,   400] loss: 1.208\n",
      "[19,   500] loss: 1.225\n",
      "[20,   100] loss: 1.180\n",
      "[20,   200] loss: 1.181\n",
      "[20,   300] loss: 1.194\n",
      "[20,   400] loss: 1.194\n",
      "[20,   500] loss: 1.152\n",
      "[21,   100] loss: 1.180\n",
      "[21,   200] loss: 1.203\n",
      "[21,   300] loss: 1.153\n",
      "[21,   400] loss: 1.122\n",
      "[21,   500] loss: 1.144\n",
      "[22,   100] loss: 1.128\n",
      "[22,   200] loss: 1.166\n",
      "[22,   300] loss: 1.146\n",
      "[22,   400] loss: 1.118\n",
      "[22,   500] loss: 1.136\n",
      "[23,   100] loss: 1.128\n",
      "[23,   200] loss: 1.136\n",
      "[23,   300] loss: 1.116\n",
      "[23,   400] loss: 1.133\n",
      "[23,   500] loss: 1.096\n",
      "[24,   100] loss: 1.091\n",
      "[24,   200] loss: 1.085\n",
      "[24,   300] loss: 1.109\n",
      "[24,   400] loss: 1.076\n",
      "[24,   500] loss: 1.114\n",
      "[25,   100] loss: 1.081\n",
      "[25,   200] loss: 1.087\n",
      "[25,   300] loss: 1.075\n",
      "[25,   400] loss: 1.061\n",
      "[25,   500] loss: 1.081\n",
      "[26,   100] loss: 1.069\n",
      "[26,   200] loss: 1.072\n",
      "[26,   300] loss: 1.066\n",
      "[26,   400] loss: 1.066\n",
      "[26,   500] loss: 1.062\n",
      "[27,   100] loss: 1.055\n",
      "[27,   200] loss: 1.026\n",
      "[27,   300] loss: 1.061\n",
      "[27,   400] loss: 1.042\n",
      "[27,   500] loss: 1.034\n",
      "[28,   100] loss: 1.034\n",
      "[28,   200] loss: 1.013\n",
      "[28,   300] loss: 1.032\n",
      "[28,   400] loss: 1.033\n",
      "[28,   500] loss: 1.038\n",
      "[29,   100] loss: 1.026\n",
      "[29,   200] loss: 1.005\n",
      "[29,   300] loss: 1.035\n",
      "[29,   400] loss: 1.016\n",
      "[29,   500] loss: 1.002\n",
      "[30,   100] loss: 0.995\n",
      "[30,   200] loss: 1.014\n",
      "[30,   300] loss: 0.997\n",
      "[30,   400] loss: 1.010\n",
      "[30,   500] loss: 0.991\n",
      "[31,   100] loss: 0.987\n",
      "[31,   200] loss: 0.996\n",
      "[31,   300] loss: 1.004\n",
      "[31,   400] loss: 0.989\n",
      "[31,   500] loss: 0.976\n",
      "[32,   100] loss: 0.976\n",
      "[32,   200] loss: 0.998\n",
      "[32,   300] loss: 0.930\n",
      "[32,   400] loss: 0.977\n",
      "[32,   500] loss: 0.943\n",
      "[33,   100] loss: 0.949\n",
      "[33,   200] loss: 0.948\n",
      "[33,   300] loss: 0.977\n",
      "[33,   400] loss: 0.974\n",
      "[33,   500] loss: 0.973\n",
      "[34,   100] loss: 0.951\n",
      "[34,   200] loss: 0.958\n",
      "[34,   300] loss: 0.944\n",
      "[34,   400] loss: 0.928\n",
      "[34,   500] loss: 0.948\n",
      "[35,   100] loss: 0.927\n",
      "[35,   200] loss: 0.936\n",
      "[35,   300] loss: 0.927\n",
      "[35,   400] loss: 0.945\n",
      "[35,   500] loss: 0.927\n",
      "[36,   100] loss: 0.903\n",
      "[36,   200] loss: 0.944\n",
      "[36,   300] loss: 0.921\n",
      "[36,   400] loss: 0.923\n",
      "[36,   500] loss: 0.924\n",
      "[37,   100] loss: 0.901\n",
      "[37,   200] loss: 0.917\n",
      "[37,   300] loss: 0.903\n",
      "[37,   400] loss: 0.924\n",
      "[37,   500] loss: 0.917\n",
      "[38,   100] loss: 0.918\n",
      "[38,   200] loss: 0.898\n",
      "[38,   300] loss: 0.893\n",
      "[38,   400] loss: 0.902\n",
      "[38,   500] loss: 0.908\n",
      "[39,   100] loss: 0.910\n",
      "[39,   200] loss: 0.915\n",
      "[39,   300] loss: 0.893\n",
      "[39,   400] loss: 0.889\n",
      "[39,   500] loss: 0.894\n",
      "[40,   100] loss: 0.879\n",
      "[40,   200] loss: 0.884\n",
      "[40,   300] loss: 0.893\n",
      "[40,   400] loss: 0.900\n",
      "[40,   500] loss: 0.884\n",
      "[41,   100] loss: 0.880\n",
      "[41,   200] loss: 0.884\n",
      "[41,   300] loss: 0.873\n",
      "[41,   400] loss: 0.858\n",
      "[41,   500] loss: 0.876\n",
      "[42,   100] loss: 0.879\n",
      "[42,   200] loss: 0.864\n",
      "[42,   300] loss: 0.851\n",
      "[42,   400] loss: 0.861\n",
      "[42,   500] loss: 0.857\n",
      "[43,   100] loss: 0.838\n",
      "[43,   200] loss: 0.868\n",
      "[43,   300] loss: 0.859\n",
      "[43,   400] loss: 0.854\n",
      "[43,   500] loss: 0.862\n",
      "[44,   100] loss: 0.838\n",
      "[44,   200] loss: 0.852\n",
      "[44,   300] loss: 0.848\n",
      "[44,   400] loss: 0.852\n",
      "[44,   500] loss: 0.855\n",
      "[45,   100] loss: 0.829\n",
      "[45,   200] loss: 0.826\n",
      "[45,   300] loss: 0.831\n",
      "[45,   400] loss: 0.833\n",
      "[45,   500] loss: 0.835\n",
      "[46,   100] loss: 0.823\n",
      "[46,   200] loss: 0.847\n",
      "[46,   300] loss: 0.856\n",
      "[46,   400] loss: 0.824\n",
      "[46,   500] loss: 0.813\n",
      "[47,   100] loss: 0.804\n",
      "[47,   200] loss: 0.827\n",
      "[47,   300] loss: 0.827\n",
      "[47,   400] loss: 0.823\n",
      "[47,   500] loss: 0.811\n",
      "[48,   100] loss: 0.783\n",
      "[48,   200] loss: 0.826\n",
      "[48,   300] loss: 0.829\n",
      "[48,   400] loss: 0.818\n",
      "[48,   500] loss: 0.800\n",
      "[49,   100] loss: 0.803\n",
      "[49,   200] loss: 0.817\n",
      "[49,   300] loss: 0.814\n",
      "[49,   400] loss: 0.802\n",
      "[49,   500] loss: 0.822\n",
      "[50,   100] loss: 0.792\n",
      "[50,   200] loss: 0.802\n",
      "[50,   300] loss: 0.798\n",
      "[50,   400] loss: 0.805\n",
      "[50,   500] loss: 0.790\n",
      "[51,   100] loss: 0.795\n",
      "[51,   200] loss: 0.799\n",
      "[51,   300] loss: 0.791\n",
      "[51,   400] loss: 0.796\n",
      "[51,   500] loss: 0.792\n",
      "[52,   100] loss: 0.787\n",
      "[52,   200] loss: 0.776\n",
      "[52,   300] loss: 0.775\n",
      "[52,   400] loss: 0.773\n",
      "[52,   500] loss: 0.794\n",
      "[53,   100] loss: 0.758\n",
      "[53,   200] loss: 0.776\n",
      "[53,   300] loss: 0.786\n",
      "[53,   400] loss: 0.794\n",
      "[53,   500] loss: 0.788\n",
      "[54,   100] loss: 0.766\n",
      "[54,   200] loss: 0.785\n",
      "[54,   300] loss: 0.786\n",
      "[54,   400] loss: 0.781\n",
      "[54,   500] loss: 0.761\n",
      "[55,   100] loss: 0.770\n",
      "[55,   200] loss: 0.773\n",
      "[55,   300] loss: 0.762\n",
      "[55,   400] loss: 0.756\n",
      "[55,   500] loss: 0.764\n",
      "[56,   100] loss: 0.764\n",
      "[56,   200] loss: 0.758\n",
      "[56,   300] loss: 0.783\n",
      "[56,   400] loss: 0.755\n",
      "[56,   500] loss: 0.761\n",
      "[57,   100] loss: 0.745\n",
      "[57,   200] loss: 0.760\n",
      "[57,   300] loss: 0.757\n",
      "[57,   400] loss: 0.741\n",
      "[57,   500] loss: 0.772\n",
      "[58,   100] loss: 0.737\n",
      "[58,   200] loss: 0.751\n",
      "[58,   300] loss: 0.730\n",
      "[58,   400] loss: 0.754\n",
      "[58,   500] loss: 0.752\n",
      "[59,   100] loss: 0.728\n",
      "[59,   200] loss: 0.743\n",
      "[59,   300] loss: 0.727\n",
      "[59,   400] loss: 0.747\n",
      "[59,   500] loss: 0.751\n",
      "[60,   100] loss: 0.739\n",
      "[60,   200] loss: 0.732\n",
      "[60,   300] loss: 0.746\n",
      "[60,   400] loss: 0.743\n",
      "[60,   500] loss: 0.752\n",
      "[61,   100] loss: 0.720\n",
      "[61,   200] loss: 0.721\n",
      "[61,   300] loss: 0.746\n",
      "[61,   400] loss: 0.727\n",
      "[61,   500] loss: 0.734\n",
      "[62,   100] loss: 0.722\n",
      "[62,   200] loss: 0.735\n",
      "[62,   300] loss: 0.726\n",
      "[62,   400] loss: 0.738\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE NETWORK\n",
    "\n",
    "# This is when things start to get interesting.\n",
    "# We simply have to loop over our data iterator, and feed the inputs to the\n",
    "# network and optimize.\n",
    "\n",
    "net.train()\n",
    "\n",
    "epochs = 200\n",
    "indice = 0\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # ZCA whitening\n",
    "        inputs = zca(inputs)\n",
    "        \n",
    "        inputs = torch.tensor(inputs, dtype=torch.float)\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "       \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('gaussian_BN', loss, indice)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # print statistics       \n",
    "        if i % 100 == 99:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss/100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        indice += 1\n",
    "        #scheduler.step()\n",
    "        #print('\\nLearning rate at this epoch is: %0.9f' % scheduler.get_lr()[0])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1pceOOJX5kck"
   },
   "outputs": [],
   "source": [
    "torch.load({\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }, \"./gaussian_BN.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGdNp8o9zJSp"
   },
   "source": [
    "### And finally we get to testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkCZ6lFXDDW2"
   },
   "source": [
    "# Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "KcfF-HJSzAuy",
    "outputId": "7ce99484-0efe-4b80-c2a8-6d45a292f234"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29ea826db00d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m testSet = torchvision.datasets.CIFAR10(\n\u001b[1;32m      4\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# where the dataset is/will be stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# creates the dataset FROM the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "testSet = torchvision.datasets.CIFAR10(\n",
    "    root='./data',  # where the dataset is/will be stored\n",
    "    train=False,  # creates the dataset FROM the test set\n",
    "    download=True,  # If True, downloads the dataset from the internet\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "# This combines a dataset and a sampler, and provides an iterable over the given dataset\n",
    "testLoader = torch.utils.data.DataLoader(\n",
    "    testSet,  # The dataset\n",
    "    batch_size=10,  # How many samples per batch to load\n",
    "    shuffle=True, # Data is reshuffled at every epoch\n",
    "    num_workers=2 # How many processes to use for data loading\n",
    ")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in testLoader:\n",
    "  \n",
    "  # We repeat ZCA whitening to replicate the normalization of the input of the training phase\n",
    "    #images = zca(images)\n",
    "    #images = torch.tensor(images, dtype=torch.float)\n",
    "\n",
    "    if use_gpu:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "\n",
    "    predicted = net(images)\n",
    "\n",
    "    for i in range(len(predicted)):\n",
    "        value, index = predicted[i].max(0)\n",
    "        total += 1\n",
    "        if labels[i] == index:\n",
    "            correct += 1\n",
    "\n",
    "print(\"Total accuracy:\", correct/total)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "forAdi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11e1a9ac34f047848baa8ffbb2a7159a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ef5113b7cf241bb86f0092178a8d1e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64b566dfbafd4603b89e434a537a6935",
      "placeholder": "​",
      "style": "IPY_MODEL_f9f368cd4cf94047bdcb77523db25b40",
      "value": " 170500096/? [00:20&lt;00:00, 30923444.34it/s]"
     }
    },
    "3fab2f120a50450188abd409c96a0336": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64b566dfbafd4603b89e434a537a6935": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b186e8dcdbd4f66b288b8b64b7232f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11e1a9ac34f047848baa8ffbb2a7159a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd2bf7be43e445549daa04091cbf1f88",
      "value": 1
     }
    },
    "999d6959943242a69f2ddb6b9bf03ce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b186e8dcdbd4f66b288b8b64b7232f4",
       "IPY_MODEL_3ef5113b7cf241bb86f0092178a8d1e6"
      ],
      "layout": "IPY_MODEL_3fab2f120a50450188abd409c96a0336"
     }
    },
    "dd2bf7be43e445549daa04091cbf1f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f9f368cd4cf94047bdcb77523db25b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
